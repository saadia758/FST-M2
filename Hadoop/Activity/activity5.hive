--create a file named EmpData.csv
$ vim EmpData.csv

--run the hive command to start the Hive CLI
$ hive

--Once Hive CLI has started, execute the following query
hive> show databases;

--create a database named office
hive> create database office;

--Set office as the default DB using the following query
hive> use office;

--create a table named employee
hive> CREATE TABLE employee
    > (id INT, name STRING, dept STRING, yoj INT, salary INT)
    > ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
    > TBLPROPERTIES ("skip.header.line.count"="1");

--use the DESCRIBE clause to see the structure of the table:
hive> DESCRIBE employee;

--To add into the employee table from a local file, enter the following query
hive> LOAD DATA LOCAL INPATH
    > '/EmpData.csv'
    > INTO TABLE employee;



--Check data that has been loaded into the employee table, use the SELECT query
hive> SELECT * FROM employee;

--To count the number of rows in the table
hive> SELECT COUNT(*) FROM employee;

--GET request from HDFS
hive> SELECT * FROM employee;

--Column operations
hive> SELECT  id, name FROM employee;
--Row operation
hive> SELECT * FROM employee WHERE salary > 30000;
--Column operation that need aggregation
hive> SELECT count(*) FROM employee; 


--Exports to LOCAL directory
hive> INSERT OVERWRITE LOCAL DIRECTORY '/export' 
    > ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
    > SELECT * FROM emp.employee;

--To view the result, you can use the cat command in regular Linux shell
$ cat /path/to/result/* > output.csv
